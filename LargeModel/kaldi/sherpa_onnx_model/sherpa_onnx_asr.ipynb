{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sherpa_onnx,sounddevice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 说话实时转写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"用户:  请输入你的问题\", end='')\n",
    "print('\\r',end='')\n",
    "print('-'*20,end='')\n",
    "print('\\r',end='')\n",
    "print('用户：',end='')\n",
    "print('您好呀,',end='', flush=True)\n",
    "print('\\r,', end='', flush=True)\n",
    "# # print('1111', end='')\n",
    "print('\\r用户：您好呀'+' '*20,end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sherpa_onnx\n",
    "import sys,os\n",
    "from kaldi.sherpa_onnx_model.stream_zipformer import microphone_endpoint\n",
    "import re\n",
    "\n",
    "#获取LargeModel所在的路径（事先将它添加到PYTHONPATH的环境变量中）\n",
    "path= [content for content in sys.path if re.match('.+:.*LargeModel$', content)][0]\n",
    "# path = \"E:\\LargeModel\".replace('\\\\','/')\n",
    "#获取stream_zipformer所在的文件路径\n",
    "path = path+'/'+'kaldi/sherpa_onnx_model/stream_zipformer'\n",
    "args_dict = {  \n",
    "    'tokens': path+'/tokens.txt', \n",
    "    'encoder': path+'/encoder-epoch-99-avg-1.onnx',\n",
    "    'decoder': path+'/decoder-epoch-99-avg-1.onnx',\n",
    "    'joiner': path+'/joiner-epoch-99-avg-1.onnx',    \n",
    "} \n",
    "sherpa_params ={\n",
    "    'rule1_min_trailing_silence':3,#2.4,#完全静默超过这个时长视为端点,结束转写\n",
    "    'rule2_min_trailing_silence':0.6,#1.2,已经解码过声音了，若静默超过这个时长，视为端点（输出一个空格）\n",
    "    'provider':'cuda',#args.provider,\n",
    "}\n",
    "#检查设备，顺便输出recongnizer\n",
    "check_recognizer= microphone_endpoint.main(args_dict, sherpa_params=sherpa_params)\n",
    "# #录音转写\n",
    "microphone_endpoint.main(args_dict,False, check_recognizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'null' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://127.0.0.1:9337/flag\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m res \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(url)\n\u001b[1;32m----> 4\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      5\u001b[0m res\n",
      "File \u001b[1;32m<string>:1\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'null' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url = 'http://127.0.0.1:9337/flag'\n",
    "res = requests.post(url,json={})\n",
    "res = eval(res.content.decode(encoding='utf-8'))[1]\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wav音频文件转写\n",
    "#### 限制多，完全不如直接使用fast_whisper转写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sherpa_onnx\n",
    "import sys\n",
    "import re\n",
    "\n",
    "#获取LargeModel所在的路径（事先将它添加到PYTHONPATH的环境变量中）\n",
    "path= [content for content in sys.path if re.match('.+:.*LargeModel$', content)][0]\n",
    "#获取stream_zipformer所在的文件路径\n",
    "path = path+'/'+'kaldi/sherpa_onnx_model/stream_zipformer'\n",
    "\n",
    "from kaldi.sherpa_onnx_model.stream_zipformer import decode_files\n",
    "# import microphone_endpoint\n",
    "args_dict = {  \n",
    "    'tokens': path+'/tokens.txt',  \n",
    "    'encoder': path+'/encoder-epoch-99-avg-1.onnx',  \n",
    "    'decoder': path+'/decoder-epoch-99-avg-1.onnx' ,  \n",
    "    'joiner': path+'/joiner-epoch-99-avg-1.onnx',    \n",
    "    'num_threads':1,\n",
    "    'decoding_method':\"greedy_search\",\n",
    "    'max_active_paths':4,\n",
    "    'lm':'',\n",
    "    'lm_scale':0.1,\n",
    "    'provider':'cuda',\n",
    "    'hotwords_file':'',\n",
    "    'hotwords_score':1.5,\n",
    "    'blank_penalty':0.0} \n",
    "\n",
    "original_stdout =  sys.stdout\n",
    "sys.stdout = open('log_maple.txt', 'w')\n",
    "#必须是wave格式，单通道，16bit---decode_files.py 的267行更改通道数，297行更改采样率\n",
    "sound_files=[path+'/test_wavs/0.wav',path+'/test_wavs/1.wav',path+'/test_wavs/2.wav',path+'/test_wavs/3.wav',path+'/test_wavs/8k.wav']\n",
    "# sound_files=[\"E:\\LargeModel\\Speech_Synthesis\\GPT_SOVITS_0训练集\\自己的模型\\姬如千泷\\素材\\音频提取.wav\"]\n",
    "\n",
    "decode_files.main(args_dict, sound_files)\n",
    "sys.stdout = original_stdout"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
