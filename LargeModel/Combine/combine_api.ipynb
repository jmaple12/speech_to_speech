{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本段尽可能通过调用api的方式进行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio,wave\n",
    "import ollama\n",
    "import warnings\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import sys\n",
    "import torch\n",
    "import re\n",
    "import logging\n",
    "import pickle\n",
    "os.environ['HF_ENDPOINT']='hf-mirror.com'#hugging_face镜像\n",
    "# os.environ['HF_HUB_OFFLINE']='0'\n",
    "#清理内存\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
    "if hasattr(torch.cuda, 'empty_cache'):\n",
    "    torch.cuda.empty_cache()\n",
    "del torch\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "original_path = sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_voice=True#是否是语音输入\n",
    "sherpa=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#语音合成：GPT_Sovits---fast_inference version\n",
    "from GPT_SoVITS.inference_webui_fast_inference_maple import handle\n",
    "\n",
    "#获取LargeModel所在的路径（事先将它添加到PYTHONPATH的环境变量中）\n",
    "path= [content for content in sys.path if re.match('.+:.*LargeModel$', content)][0]\n",
    "#ASR模型(Automatic Speech Recognition)\n",
    "if is_voice:\n",
    "    if sherpa:\n",
    "        #ASR模型：sherpa_onnx---cpu版本\n",
    "        import sherpa_onnx\n",
    "        from kaldi.sherpa_onnx_model.stream_zipformer import microphone_endpoint\n",
    "        #获取stream_zipformer所在的文件路径\n",
    "        sherpa_path = path+'/'+'kaldi/sherpa_onnx_model/stream_zipformer'\n",
    "        args_dict = {  \n",
    "            'tokens': sherpa_path+'/tokens.txt',  \n",
    "            'encoder': sherpa_path+'/encoder-epoch-99-avg-1.onnx',  \n",
    "            'decoder': sherpa_path+'/decoder-epoch-99-avg-1.onnx' ,  \n",
    "            'joiner': sherpa_path+'/joiner-epoch-99-avg-1.onnx',    \n",
    "        } \n",
    "        #检查设备，顺便输出recongnizer\n",
    "        check_recognizer= microphone_endpoint.main(args_dict)\n",
    "        del sherpa_path\n",
    "    else:\n",
    "        from Speech_to_Text.Fast_whisper.Fast_whisper import fast_whisper_realtime\n",
    "        from faster_whisper import WhisperModel\n",
    "        model_size='large-v3'\n",
    "        download_root=path+'/Speech_to_Text/fast_whisper'\n",
    "        #当download_root与模型在同一个目录时候\n",
    "        model = WhisperModel(download_root+'\\\\'+model_size, device=\"cuda\",compute_type=\"int8_float16\", download_root=download_root, local_files_only=False)\n",
    "\n",
    "\n",
    "#文本模型：chatglm\n",
    "from zhipuai import ZhipuAI\n",
    "with open(path+'/Language_Model/Text_generation/chatglm_api/api_key.txt', 'r') as chatglm_api:\n",
    "    api_key = chatglm_api.read()\n",
    "client = ZhipuAI(api_key=api_key.split('=')[1].strip('\"')) # 填写您自己的APIKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = '''\n",
    "当然，作为你的朋友，我们可以聊聊月亮、星星，或者任何你感兴趣的话题。月亮总是给人以浪漫和宁静的感觉，你有没有什么特别喜欢关于月亮的诗句或者故事想要分享的呢？\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#语音合成模型初始化\n",
    "ref_wav_path=r\"E:\\LargeModel\\Speech_Synthesis\\GPT_SOVITS_0训练集\\派蒙-效果并不好\\参考音频\\说话—既然罗莎莉亚说足迹上有元素力，用元素视野应该能很清楚地看到吧。.wav\"\n",
    "ref_wav_path = r\"E:\\LargeModel\\Speech_Synthesis\\GPT_SOVITS_0训练集\\自己的模型\\xunfeih23r\\数据集\\面试官这边临时有改动，然后，明天下午两点可以吗？.wav\"\n",
    "ref_wav_path =r\"E:\\LargeModel\\Speech_Synthesis\\GPT_SOVITS_0训练集\\自己的模型\\姬如千泷\\训练集_denoise\\这是一个传承了千年尊贵的名字。.wav\"\n",
    "prompt_text= '既然罗莎莉亚说足迹上有元素力，用元素视野应该能很清楚地看到吧。'\n",
    "prompt_text = \"面试官这边临时有改动，然后，明天下午两点可以吗？\"\n",
    "prompt_text = \"这是一个传承了千年，尊贵的名字。\"\n",
    "text='晚上好，祝你有一个甜美的睡眠！'#'你好呀！'\n",
    "# text=text1\n",
    "top_k=5\n",
    "top_p=1\n",
    "temperature=1\n",
    "how_to_cut='按标点符号切'\n",
    "# how_to_cut='凑四句一切'\n",
    "sovits_path = r\"GPT_SoVITS\\pretrained_models\\s2G488k.pth\"\n",
    "# sovits_path=r\"E:\\LargeModel\\Speech_Synthesis\\GPT_SOVITS_0训练集\\自己的模型\\xunfeih23r\\数据集\\xunfeih23r_denoise_e16_s800.pth\"\n",
    "sovits_path = r\"E:\\LargeModel\\Speech_Synthesis\\GPT_SOVITS_0训练集\\自己的模型\\姬如千泷\\训练集_denoise\\yueer_denoise_e25_s575.pth\"\n",
    "gpt_path = r\"GPT_SoVITS\\pretrained_models\\s1bert25hz-2kh-longer-epoch=68e-step=50232.ckpt\"\n",
    "# gpt_path = r\"E:\\LargeModel\\Speech_Synthesis\\GPT_SOVITS_0训练集\\自己的模型\\xunfeih23r\\数据集\\xunfeih23r_denoise-e15.ckpt\"\n",
    "gpt_path =r\"E:\\LargeModel\\Speech_Synthesis\\GPT_SOVITS_0训练集\\自己的模型\\姬如千泷\\训练集_denoise\\yueer_denoise-e25.ckpt\"\n",
    "audio_save=False\n",
    "audio_save_file='output.wav'\n",
    "text_language2='中英混合'\n",
    "prompt_language2='中英混合'\n",
    "batch_size=8         # int. batch size for inference\n",
    "split_bucket=True   # bool. whether to split the batch into multiple buckets.\n",
    "speed_factor=1.0\n",
    "ref_text_free=False\n",
    "\n",
    "top_k=5\n",
    "top_p=1\n",
    "speed_factor=1.1\n",
    "\n",
    "params={'text':text, 'text_lang':text_language2, \n",
    "            'ref_audio_path':ref_wav_path, 'prompt_text':prompt_text, \n",
    "            'prompt_lang':prompt_language2, 'top_k':top_k, \n",
    "            'top_p':top_p, 'temperature':temperature, \n",
    "            'text_split_method':how_to_cut, 'batch_size':batch_size, \n",
    "            'speed_factor':speed_factor, 'ref_text_free':ref_text_free,\n",
    "            'split_bucket':split_bucket, 'audio_save':audio_save, \n",
    "            'audio_save_file':audio_save_file, 'mygpt_path':gpt_path, 'mysovits_path':sovits_path}\n",
    "\n",
    "def tts(params):\n",
    "    # 将标准输出流重定向到空设备\n",
    "    original_stdout =  sys.stdout\n",
    "    sys.stdout = open('log_maple.txt', 'w')\n",
    "    handle(**params)\n",
    "    sys.stdout = original_stdout\n",
    "    logging.getLogger().setLevel(logging.WARNING)\n",
    "tts(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#拜拜结束对话\n",
    "#对话前删除临时录音文件\n",
    "def delete_files(folder_path):\n",
    "    file_list = glob.glob(folder_path + '/*')\n",
    "    for file_path in file_list:\n",
    "        if os.path.isfile(file_path):\n",
    "            if '.' in file_path and file_path.split('.')[0].split('/')[-1][:4]=='test':\n",
    "                os.remove(file_path)\n",
    "\n",
    "# 调用函数删除文件夹中的文件\n",
    "audio_file_path = 'test'\n",
    "delete_files(audio_file_path)\n",
    "\n",
    "#语音提醒可以对话了\n",
    "params['text'] =\"您好，您现在可以跟我进行对话了！\" \n",
    "tts(params)\n",
    "\n",
    "outfile_name=audio_file_path+'\\\\test.mp3'\n",
    "lc =0 #对话轮次，用于录音文件的名称存储\n",
    "messages = [{\"role\": \"system\", \"content\":\"您将以朋友的身份与用户进行聊天对话。\"}]\n",
    "tokens_use = 0\n",
    "\n",
    "awake=False #表示是否是语音唤醒部分   \n",
    "while(True):#语音对话的循环\n",
    "    #ASR\n",
    "    if is_voice:\n",
    "        if sherpa:\n",
    "            #last_result：一轮的最后一段结果, lc_result：一轮的结果\n",
    "            last_result, lc_result = microphone_endpoint.main(args_dict, False, check_recognizer)\n",
    "        else:\n",
    "            delayTime=0.8\n",
    "            tendure=3\n",
    "            mindb=2000\n",
    "            last_result, lc_result=fast_whisper_realtime(audio_file_path, model, delayTime, tendure, mindb)\n",
    "        #语音唤醒\n",
    "        if awake:\n",
    "            if last_result in {\"老铁你好\",\"千龙你好\",\"乾隆你好\",\"青龙你好\",\n",
    "                            \"天龙你好\",\"钱老你好\",\"前路你好\",\"成龙你好\"}:\n",
    "                params['text']='我在呢！'\n",
    "                tts(params)\n",
    "                awake=False\n",
    "            else:\n",
    "                time.sleep(0.5)\n",
    "            continue\n",
    "        #结束语\n",
    "\n",
    "        if re.sub(r'[ .。！!?？-]','', last_result).lower() in {'拜拜','byebye','再见','掰掰'}:\n",
    "            lc=-1\n",
    "            result=last_result\n",
    "        \n",
    "        if len(lc_result)==0:\n",
    "            print('\\n', '*'*40)\n",
    "            print(' '*5, '您的对话已超时，请重新对话！')\n",
    "            print('\\n', '*'*40)\n",
    "            awake=True\n",
    "            continue\n",
    "\n",
    "        print()\n",
    "        if lc==-1:\n",
    "            print(result)\n",
    "            break\n",
    "        lc +=1\n",
    "        question = lc_result\n",
    "        # if (len(question)==0)|(question=='拜拜'):\n",
    "        #     break\n",
    "    else:\n",
    "        question = input('请输入你的问题：回车退出')\n",
    "        if len(question)==0:\n",
    "            lc=-1\n",
    "            break\n",
    "        print('用户：', end='')\n",
    "        print(question)\n",
    "\n",
    "    #--------------------Text to Text\n",
    "    #剪切历史记录每9条删除前面4条\n",
    "    if len(messages)>9:\n",
    "        for i in range(4):\n",
    "            messages.pop(1)\n",
    "    print('智谱：', end='')\n",
    "    messages.append({\"role\": \"user\", \"content\": question})\n",
    "    llm_model = 'glm-4'\n",
    "    response = client.chat.completions.create(\n",
    "        model=llm_model,  # 填写需要调用的模型名称\n",
    "        messages=messages,\n",
    "        # max_tokens=1024,#所以历史记录加起来不能超过这个长度\n",
    "        stream=True,\n",
    "    )\n",
    "    answer=''\n",
    "    outword=''\n",
    "    for chunk in response:\n",
    "        answer_chunk = chunk.choices[0].delta.content\n",
    "        temp_split_left = answer_chunk\n",
    "        temp_split_right = ''\n",
    "        #是否播放音频——初始为False\n",
    "        is_tts=False\n",
    "        #'^(.\\n)|(^[。\\n]).*'任意\\n在前两位及开头是。\n",
    "        if re.search('^(.\\n)|(^[。\\n]).*',answer_chunk):\n",
    "            #智谱的\\n可能在chunk的中间，把最后一个\\n之前的视为上一句\n",
    "            temp_split = re.split('\\n+', answer_chunk)\n",
    "            if len(temp_split)>1:\n",
    "                temp_split_left = '\\n'.join(temp_split[:-1])+'\\n'\n",
    "                temp_split_right = temp_split[-1]\n",
    "            is_tts=True \n",
    "        outword += temp_split_left\n",
    "        answer += temp_split_left\n",
    "        print(temp_split_left, end='', flush=True)\n",
    "        if is_tts:\n",
    "            params['text']= outword\n",
    "            tts(params)\n",
    "            outword=temp_split_right\n",
    "            answer += temp_split_right\n",
    "            print(temp_split_right, end='', flush=True)\n",
    "    if len(outword)!=0:\n",
    "        params['text']=outword\n",
    "        tts(params)\n",
    "    print('##end', end='')\n",
    "    params['text'] ='##end'\n",
    "    tts(params)\n",
    "    print()\n",
    "    tokens_use += chunk.usage.total_tokens\n",
    "    messages.append({\"role\": \"assistant\", \"content\": answer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#存储聊天记录\n",
    "with open(r'E:\\LargeModel\\Language_Model\\Text_generation\\chatglm_api\\chat_message.pkl', 'wb') as save_file:\n",
    "    pickle.dump(messages, save_file)\n",
    "tokens_use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
