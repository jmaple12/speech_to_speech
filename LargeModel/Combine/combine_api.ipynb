{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本段尽可能通过调用api的方式进行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio,wave\n",
    "import ollama\n",
    "import warnings\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import torch\n",
    "import re\n",
    "import logging\n",
    "import pickle\n",
    "os.environ['HF_ENDPOINT']='hf-mirror.com'#hugging_face镜像\n",
    "# os.environ['HF_HUB_OFFLINE']='0'\n",
    "#清理内存\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
    "if hasattr(torch.cuda, 'empty_cache'):\n",
    "    torch.cuda.empty_cache()\n",
    "del torch\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#语音合成：GPT_Sovits---fast_inference version\n",
    "sys.path.insert(0,'../Speech_Synthesis\\GPT_Sovits\\GPT-SoVITS-beta\\GPT-SoVITS-beta_fast_inference_0316\\GPT_SoVITS')\n",
    "from inference_webui_fast_inference_maple import handle\n",
    "\n",
    "#ASR模型：sherpa_onnx---cpu版本\n",
    "import sherpa_onnx\n",
    "path = 'E:/LargeModel/kaldi/sherpa_onnx_model/stream_zipformer'\n",
    "sys.path.append(path)\n",
    "import microphone_endpoint\n",
    "args_dict = {  \n",
    "    'tokens': path+'/tokens.txt',  \n",
    "    'encoder': path+'/encoder-epoch-99-avg-1.onnx',  \n",
    "    'decoder': path+'/decoder-epoch-99-avg-1.onnx' ,  \n",
    "    'joiner': path+'/joiner-epoch-99-avg-1.onnx',    \n",
    "} \n",
    "#检查设备，顺便输出recongnizer\n",
    "check_recognizer= microphone_endpoint.main(args_dict)\n",
    "\n",
    "#文本模型：chatglm\n",
    "from zhipuai import ZhipuAI\n",
    "with open(r\"E:\\LargeModel\\Language_Model\\Text_generation\\chatglm_api\\api_key.txt\", 'r') as chatglm_api:\n",
    "    api_key = chatglm_api.read()\n",
    "client = ZhipuAI(api_key=api_key.split('=')[1].strip('\"')) # 填写您自己的APIKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#语音合成模型初始化\n",
    "ref_wav_path=\"E:\\LargeModel\\Speech_Synthesis\\GPT_Sovits\\GPT-SoVITS-beta\\派蒙--官方给的\\参考音频\\说话—既然罗莎莉亚说足迹上有元素力，用元素视野应该能很清楚地看到吧。.wav\"\n",
    "prompt_text= '既然罗莎莉亚说足迹上有元素力，用元素视野应该能很清楚地看到吧。'\n",
    "text='晚上好，祝你有一个甜美的睡眠！'#'你好呀！'\n",
    "top_k=5\n",
    "top_p=1\n",
    "temperature=1\n",
    "how_to_cut='按标点符号切'\n",
    "sovits_path = r\"E:\\LargeModel\\Speech_Synthesis\\GPT_Sovits\\GPT-SoVITS-beta\\GPT-SoVITS-beta_fast_inference_0316\\GPT_SoVITS\\pretrained_models\\s2G488k.pth\"\n",
    "gpt_path = r\"E:\\LargeModel\\Speech_Synthesis\\GPT_Sovits\\GPT-SoVITS-beta\\GPT-SoVITS-beta_fast_inference_0316\\GPT_SoVITS\\pretrained_models\\s1bert25hz-2kh-longer-epoch=68e-step=50232.ckpt\"\n",
    "audio_save=False\n",
    "audio_save_file='output.wav'\n",
    "text_language2='中英混合'\n",
    "prompt_language2='中英混合'\n",
    "batch_size=6         # int. batch size for inference\n",
    "split_bucket=True   # bool. whether to split the batch into multiple buckets.\n",
    "speed_factor=1.0\n",
    "ref_text_free=False\n",
    "\n",
    "params={'text':text, 'text_lang':text_language2, \n",
    "            'ref_audio_path':ref_wav_path, 'prompt_text':prompt_text, \n",
    "            'prompt_lang':prompt_language2, 'top_k':top_k, \n",
    "            'top_p':top_p, 'temperature':temperature, \n",
    "            'text_split_method':how_to_cut, 'batch_size':batch_size, \n",
    "            'speed_factor':speed_factor, 'ref_text_free':ref_text_free,\n",
    "            'split_bucket':split_bucket, 'audio_save':audio_save, \n",
    "            'audio_save_file':audio_save_file, 'mygpt_path':gpt_path, 'mysovits_path':sovits_path}\n",
    "\n",
    "def tts(params):\n",
    "    # 将标准输出流重定向到空设备\n",
    "    original_stdout =  sys.stdout\n",
    "    sys.stdout = open('log_maple.txt', 'w')\n",
    "    handle(**params)\n",
    "    sys.stdout = original_stdout\n",
    "    logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "tts(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#拜拜结束对话\n",
    "#对话前删除临时录音文件\n",
    "def delete_files(folder_path):\n",
    "    file_list = glob.glob(folder_path + '/*')\n",
    "    for file_path in file_list:\n",
    "        if os.path.isfile(file_path):\n",
    "            if '.' in file_path and file_path.split('.')[0].split('/')[-1][:4]=='test':\n",
    "                os.remove(file_path)\n",
    "\n",
    "# 调用函数删除文件夹中的文件\n",
    "audio_file_path = 'test'\n",
    "delete_files(audio_file_path)\n",
    "\n",
    "#语音提醒可以对话了\n",
    "params['text'] =\"您好，您现在可以跟我进行对话了！\" \n",
    "tts(params)\n",
    "\n",
    "outfile_name=audio_file_path+'\\\\test.mp3'\n",
    "lc =0 #对话轮次，用于录音文件的名称存储\n",
    "messages = [{\"role\": \"system\", \"content\":\"您是一个知心朋友，你的任务是和用户聊天。\"}]\n",
    "tokens_use = 0\n",
    "while(True):\n",
    "    #ASR\n",
    "    last_result, lc_result = microphone_endpoint.main(args_dict, False, check_recognizer)\n",
    "    #结束语\n",
    "    if re.sub(r'[ .。！!?？-]','', last_result).lower() in {'拜拜','byebye','再见','掰掰'}:\n",
    "        lc=-1\n",
    "        result=last_result\n",
    "    \n",
    "    if len(lc_result)==0:\n",
    "        print('\\n', '*'*40)\n",
    "        print(' '*5, '您的对话已超时，请重新对话！')\n",
    "        print('\\n', '*'*40)\n",
    "        break\n",
    "\n",
    "    print()\n",
    "    #每轮的文本互动开始\n",
    "    # print('Bot:',end='')\n",
    "    if lc==-1:\n",
    "        print(result)\n",
    "        break\n",
    "    lc +=1\n",
    "    #--------------------Text to Text\n",
    "    #剪切历史记录每9条删除前面4条\n",
    "    if len(messages)>7:\n",
    "        for i in range(4):\n",
    "            messages.pop(1)\n",
    "    \n",
    "    question = lc_result\n",
    "    if (len(question)==0)|(question=='拜拜'):\n",
    "        break\n",
    "    print('智谱：', end='')\n",
    "    messages.append({\"role\": \"user\", \"content\": question})\n",
    "    model = 'glm-4'\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,  # 填写需要调用的模型名称\n",
    "        messages=messages,\n",
    "        # max_tokens=1024,#所以历史记录加起来不能超过这个长度\n",
    "        stream=True,\n",
    "    )\n",
    "    answer=''\n",
    "    outword=''\n",
    "    for chunk in response:\n",
    "        answer_chunk = chunk.choices[0].delta.content\n",
    "        outword += answer_chunk\n",
    "        answer+= answer_chunk\n",
    "        print(answer_chunk, end='', flush=True)\n",
    "        if answer_chunk in {\"\\n\"}:\n",
    "            params['text']=outword\n",
    "            tts(params)\n",
    "            outword=''\n",
    "    if len(outword)!=0:\n",
    "        params['text']=outword\n",
    "        tts(params)\n",
    "    print('####end', end='')\n",
    "    params['text'] ='####end'\n",
    "    tts(params)\n",
    "    print()\n",
    "    tokens_use += chunk.usage.total_tokens\n",
    "    messages.append({\"role\": \"assistant\", \"content\": answer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#存储聊天记录\n",
    "with open(r'E:\\LargeModel\\Language_Model\\Text_generation\\chatglm_api\\chat_message.pkl', 'wb') as save_file:\n",
    "    pickle.dump(messages, save_file)\n",
    "tokens_use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
