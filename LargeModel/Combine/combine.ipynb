{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio,wave\n",
    "import ollama\n",
    "import warnings\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import torch\n",
    "import re\n",
    "import logging\n",
    "os.environ['HF_ENDPOINT']='hf-mirror.com'#hugging_face镜像\n",
    "# os.environ['HF_HUB_OFFLINE']='0'\n",
    "\n",
    "#清理内存\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
    "if hasattr(torch.cuda, 'empty_cache'):\n",
    "    torch.cuda.empty_cache()\n",
    "del torch\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "original_path = sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------TTS Config---------------------------------------------\n",
      "device              : cuda\n",
      "is_half             : True\n",
      "t2s_weights_path    : GPT_SoVITS\\pretrained_models\\s1bert25hz-2kh-longer-epoch=68e-step=50232.ckpt\n",
      "vits_weights_path   : GPT_SoVITS\\pretrained_models\\s2G488k.pth\n",
      "bert_base_path      : GPT_SoVITS\\pretrained_models\\chinese-roberta-wwm-ext-large\n",
      "cnhuhbert_base_path : GPT_SoVITS\\pretrained_models\\chinese-hubert-base\n",
      "flash_attn_enabled  : True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Loading Text2Semantic weights from GPT_SoVITS\\pretrained_models\\s1bert25hz-2kh-longer-epoch=68e-step=50232.ckpt\n",
      "Using Flash Attention\n",
      "Loading VITS weights from GPT_SoVITS\\pretrained_models\\s2G488k.pth\n",
      "Loading BERT weights from GPT_SoVITS\\pretrained_models\\chinese-roberta-wwm-ext-large\n",
      "Loading CNHuBERT weights from GPT_SoVITS\\pretrained_models\\chinese-hubert-base\n"
     ]
    }
   ],
   "source": [
    "# #pyttsx3文转语音\n",
    "# import pyttsx3\n",
    "# sys.path.append('../text_to_voice')\n",
    "# from pyttsx3_def import text_voice##\n",
    "# engine = pyttsx3.init()\n",
    "# engine = text_voice(engine,rate=130)\n",
    "# (r,ve,vs) = (engine.getProperty('rate'),engine.getProperty('volume'), engine.getProperty('voices'))\n",
    "# print('目前语速是：',r,'\\t','语音音量是:',ve)\n",
    "\n",
    "#导入语音合成模型\n",
    "#选择运行哪一个版本\n",
    "version_choose = '0306fix' \n",
    "version_choose = 'fast_inference'\n",
    "\n",
    "if version_choose == 'fast_inference' :\n",
    "    from GPT_SoVITS.inference_webui_fast_inference_maple import handle\n",
    "\n",
    "elif version_choose == '0306fix':\n",
    "    from GPT_SoVITS.inference_maple import handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 Microsoft Sound Mapper - Input, MME (2 in, 0 out)\n",
      ">  1 耳机 (EDIFIER W820NB Hands-Free A, MME (2 in, 0 out)\n",
      "   2 麦克风阵列 (适用于数字麦克风的英特尔® 智音技术), MME (2 in, 0 out)\n",
      "   3 Microsoft Sound Mapper - Output, MME (0 in, 2 out)\n",
      "<  4 耳机 (EDIFIER W820NB Stereo), MME (0 in, 2 out)\n",
      "   5 扬声器 (2- Realtek(R) Audio), MME (0 in, 2 out)\n",
      "   6 耳机 (EDIFIER W820NB Hands-Free A, MME (0 in, 2 out)\n",
      "   7 主声音捕获驱动程序, Windows DirectSound (2 in, 0 out)\n",
      "   8 耳机 (EDIFIER W820NB Hands-Free AG Audio), Windows DirectSound (2 in, 0 out)\n",
      "   9 麦克风阵列 (适用于数字麦克风的英特尔® 智音技术), Windows DirectSound (2 in, 0 out)\n",
      "  10 主声音驱动程序, Windows DirectSound (0 in, 2 out)\n",
      "  11 耳机 (EDIFIER W820NB Stereo), Windows DirectSound (0 in, 2 out)\n",
      "  12 扬声器 (2- Realtek(R) Audio), Windows DirectSound (0 in, 8 out)\n",
      "  13 耳机 (EDIFIER W820NB Hands-Free AG Audio), Windows DirectSound (0 in, 1 out)\n",
      "  14 扬声器 (2- Realtek(R) Audio), Windows WASAPI (0 in, 8 out)\n",
      "  15 耳机 (EDIFIER W820NB Stereo), Windows WASAPI (0 in, 2 out)\n",
      "  16 耳机 (EDIFIER W820NB Hands-Free AG Audio), Windows WASAPI (0 in, 1 out)\n",
      "  17 耳机 (EDIFIER W820NB Hands-Free AG Audio), Windows WASAPI (1 in, 0 out)\n",
      "  18 麦克风阵列 (适用于数字麦克风的英特尔® 智音技术), Windows WASAPI (2 in, 0 out)\n",
      "  19 耳机 (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\n",
      ";(WH-1000XM4)), Windows WDM-KS (0 in, 1 out)\n",
      "  20 耳机 (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\n",
      ";(WH-1000XM4)), Windows WDM-KS (1 in, 0 out)\n",
      "  21 耳机 (), Windows WDM-KS (0 in, 2 out)\n",
      "  22 Speakers 1 (Realtek HD Audio output with SST), Windows WDM-KS (0 in, 2 out)\n",
      "  23 Speakers 2 (Realtek HD Audio output with SST), Windows WDM-KS (0 in, 8 out)\n",
      "  24 电脑扬声器 (Realtek HD Audio output with SST), Windows WDM-KS (2 in, 0 out)\n",
      "  25 麦克风 (Realtek HD Audio Mic input), Windows WDM-KS (2 in, 0 out)\n",
      "  26 立体声混音 (Realtek HD Audio Stereo input), Windows WDM-KS (2 in, 0 out)\n",
      "  27 Headphones 1 (Realtek HD Audio 2nd output with SST), Windows WDM-KS (0 in, 2 out)\n",
      "  28 Headphones 2 (Realtek HD Audio 2nd output with SST), Windows WDM-KS (0 in, 8 out)\n",
      "  29 电脑扬声器 (Realtek HD Audio 2nd output with SST), Windows WDM-KS (2 in, 0 out)\n",
      "  30 线路 (), Windows WDM-KS (2 in, 0 out)\n",
      "  31 Output (@System32\\drivers\\bthhfenum.sys,#4;%1 Hands-Free HF Audio%0\n",
      ";(OPPO Reno5 Pro+ 5G)), Windows WDM-KS (0 in, 1 out)\n",
      "  32 Input (@System32\\drivers\\bthhfenum.sys,#4;%1 Hands-Free HF Audio%0\n",
      ";(OPPO Reno5 Pro+ 5G)), Windows WDM-KS (1 in, 0 out)\n",
      "  33 Output (@System32\\drivers\\bthhfenum.sys,#4;%1 Hands-Free HF Audio%0\n",
      ";(OPPO R11t)), Windows WDM-KS (0 in, 1 out)\n",
      "  34 Input (@System32\\drivers\\bthhfenum.sys,#4;%1 Hands-Free HF Audio%0\n",
      ";(OPPO R11t)), Windows WDM-KS (1 in, 0 out)\n",
      "  35 耳机 (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\n",
      ";(OPPO Enco Air3)), Windows WDM-KS (0 in, 1 out)\n",
      "  36 耳机 (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\n",
      ";(OPPO Enco Air3)), Windows WDM-KS (1 in, 0 out)\n",
      "  37 耳机 (), Windows WDM-KS (0 in, 2 out)\n",
      "  38 线路 (), Windows WDM-KS (2 in, 0 out)\n",
      "  39 麦克风阵列 1 (), Windows WDM-KS (2 in, 0 out)\n",
      "  40 麦克风阵列 2 (), Windows WDM-KS (2 in, 0 out)\n",
      "  41 麦克风阵列 3 (), Windows WDM-KS (4 in, 0 out)\n",
      "  42 Output (@System32\\drivers\\bthhfenum.sys,#4;%1 Hands-Free HF Audio%0\n",
      ";(金伍珑的iPad)), Windows WDM-KS (0 in, 1 out)\n",
      "  43 Input (@System32\\drivers\\bthhfenum.sys,#4;%1 Hands-Free HF Audio%0\n",
      ";(金伍珑的iPad)), Windows WDM-KS (1 in, 0 out)\n",
      "  44 耳机 (), Windows WDM-KS (0 in, 2 out)\n",
      "  45 耳机 (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\n",
      ";(EDIFIER W820NB)), Windows WDM-KS (0 in, 1 out)\n",
      "  46 耳机 (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\n",
      ";(EDIFIER W820NB)), Windows WDM-KS (1 in, 0 out)\n",
      "  47 线路 (), Windows WDM-KS (2 in, 0 out)\n",
      "Use default device: 耳机 (EDIFIER W820NB Hands-Free A\n",
      "machine is found!\n"
     ]
    }
   ],
   "source": [
    "#声音转文本模型加载\n",
    "model_choose='sherpa_onnx'#fast_whisper, whisper, sherpa_onnx\n",
    "# model_choose='faster_whisper'\n",
    "# model_choose='whisper'\n",
    "\n",
    "#获取LargeModel所在的路径（事先将它添加到PYTHONPATH的环境变量中）\n",
    "path= [content for content in sys.path if re.match('.+:.*LargeModel$', content)][0]\n",
    "\n",
    "if model_choose=='faster_whisper':\n",
    "    from voice_record.voice_record_def import listen#记录输入的语音\n",
    "    from Speech_to_Text.Fast_whisper.Fast_whisper import fast_whisper_opt\n",
    "    from faster_whisper import WhisperModel\n",
    "\n",
    "    model_size = \"small\"\n",
    "    # model_size='large-v3'\n",
    "    download_root=path+'/Speech_to_Text/fast_whisper'\n",
    "    #当download_root与模型在同一个目录时候\n",
    "    model = WhisperModel(download_root+'\\\\'+model_size, device=\"cuda\", compute_type=\"float16\", download_root=download_root, local_files_only=False)\n",
    "\n",
    "#whisper十分垃圾\n",
    "elif model_choose=='whisper':\n",
    "    # #whisper\n",
    "    import whisper\n",
    "    from voice_record.voice_record_def import listen#记录输入的语音\n",
    "    from Speech_to_Text.Whisper.Whisper import whisper_output\n",
    "    model_path = path+'/Speech_to_Text/Whisper/Model'\n",
    "    # model= whisper.load_model(name='small', download_root=model_path)#device='cuda:0'\n",
    "    model= whisper.load_model(name='small', download_root=model_path)#device='cuda:0'\n",
    "\n",
    "elif model_choose == 'sherpa_onnx':\n",
    "    import sherpa_onnx\n",
    "    from kaldi.sherpa_onnx_model.stream_zipformer import microphone_endpoint\n",
    "    sherpa_path = path+'/'+'kaldi/sherpa_onnx_model/stream_zipformer'\n",
    "    args_dict = {  \n",
    "        'tokens': sherpa_path+'/tokens.txt',  \n",
    "        'encoder': sherpa_path+'/encoder-epoch-99-avg-1.onnx',  \n",
    "        'decoder': sherpa_path+'/decoder-epoch-99-avg-1.onnx' ,  \n",
    "        'joiner': sherpa_path+'/joiner-epoch-99-avg-1.onnx',    \n",
    "    } \n",
    "    #检查设备，顺便输出recongnizer\n",
    "    check_recognizer= microphone_endpoint.main(args_dict)\n",
    "else:\n",
    "    print('Choose unfound asr model！')\n",
    "\n",
    "\n",
    "#文本对话初始化\n",
    "text_text_model='qwen:4b-chat-v1.5-q6_K'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:jieba_fast:Building prefix dict from the default dictionary ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from cache C:\\Users\\maple\\AppData\\Local\\Temp\\jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:jieba_fast:Loading model from cache C:\\Users\\maple\\AppData\\Local\\Temp\\jieba.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.580 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:jieba_fast:Loading model cost 0.580 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:jieba_fast:Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "#语音合成模型初始化\n",
    "ref_wav_path=r\"E:\\LargeModel\\Speech_Synthesis\\GPT_SOVITS_0训练集\\派蒙-效果并不好\\参考音频\\说话—既然罗莎莉亚说足迹上有元素力，用元素视野应该能很清楚地看到吧。.wav\"\n",
    "ref_wav_path = r\"E:\\LargeModel\\Speech_Synthesis\\GPT_SOVITS_0训练集\\自己的模型\\xunfeih23r\\数据集\\面试官这边临时有改动，然后，明天下午两点可以吗？.wav\"\n",
    "ref_wav_path =r\"E:\\LargeModel\\Speech_Synthesis\\GPT_SOVITS_0训练集\\自己的模型\\姬如千泷\\训练集_denoise\\这是一个传承了千年尊贵的名字。.wav\"\n",
    "prompt_text= '既然罗莎莉亚说足迹上有元素力，用元素视野应该能很清楚地看到吧。'\n",
    "prompt_text = \"面试官这边临时有改动，然后，明天下午两点可以吗？\"\n",
    "prompt_text = \"这是一个传承了千年，尊贵的名字。\"\n",
    "prompt_language='zh'\n",
    "text='晚上好，祝你有一个甜美的睡眠！'#'你好呀！'\n",
    "text_language='zh'\n",
    "ref_free=False\n",
    "start=False\n",
    "top_k=5\n",
    "top_p=1\n",
    "temperature=1\n",
    "# how_to_cut='凑四句一切'\n",
    "how_to_cut='按标点符号切'\n",
    "\n",
    "#0306fix版本有流式输出，输出快了一些，但是中间有停顿\n",
    "stream=True\n",
    "audio_save=False\n",
    "audio_save_file='./output.wav'\n",
    "\n",
    "sovits_path = r\"GPT_SoVITS\\pretrained_models\\s2G488k.pth\"\n",
    "# sovits_path=r\"E:\\LargeModel\\Speech_Synthesis\\GPT_SOVITS_0训练集\\自己的模型\\xunfeih23r\\数据集\\xunfeih23r_denoise_e16_s800.pth\"\n",
    "sovits_path = r\"E:\\LargeModel\\Speech_Synthesis\\GPT_SOVITS_0训练集\\自己的模型\\姬如千泷\\训练集_denoise\\yueer_denoise_e25_s575.pth\"\n",
    "gpt_path = r\"GPT_SoVITS\\pretrained_models\\s1bert25hz-2kh-longer-epoch=68e-step=50232.ckpt\"\n",
    "# gpt_path = r\"E:\\LargeModel\\Speech_Synthesis\\GPT_SOVITS_0训练集\\自己的模型\\xunfeih23r\\数据集\\xunfeih23r_denoise-e15.ckpt\"\n",
    "gpt_path =r\"E:\\LargeModel\\Speech_Synthesis\\GPT_SOVITS_0训练集\\自己的模型\\姬如千泷\\训练集_denoise\\yueer_denoise-e25.ckpt\"\n",
    "\n",
    "audio_save=False\n",
    "audio_save_file='output.wav'\n",
    "#---------------------------------------------------#\n",
    "text_language2='中英混合'\n",
    "prompt_language2='中英混合'\n",
    "batch_size=6         # int. batch size for inference\n",
    "split_bucket=True   # bool. whether to split the batch into multiple buckets.\n",
    "speed_factor=1.0\n",
    "ref_text_free=False\n",
    "\n",
    "if version_choose == 'fast_inference':\n",
    "    params={'text':text, 'text_lang':text_language2, \n",
    "              'ref_audio_path':ref_wav_path, 'prompt_text':prompt_text, \n",
    "              'prompt_lang':prompt_language2, 'top_k':top_k, \n",
    "              'top_p':top_p, 'temperature':temperature, \n",
    "              'text_split_method':how_to_cut, 'batch_size':batch_size, \n",
    "              'speed_factor':speed_factor, 'ref_text_free':ref_text_free,\n",
    "              'split_bucket':split_bucket, 'audio_save':audio_save, \n",
    "              'audio_save_file':audio_save_file, 'mygpt_path':gpt_path, 'mysovits_path':sovits_path}\n",
    "    \n",
    "elif version_choose == '0306fix':\n",
    "    params = {'ref_wav_path':ref_wav_path, 'prompt_text':prompt_text, 'prompt_language':prompt_language, 'text':text, 'text_language':text_language, 'sovits_path':sovits_path, 'gpt_path':gpt_path, 'start':start, 'top_k':top_k, 'top_p':top_p, 'temperature':temperature, 'how_to_cut':how_to_cut, 'ref_free':ref_free, 'stream':stream, 'audio_save':audio_save, 'audio_save_file':audio_save_file}\n",
    "\n",
    "\n",
    "def tts(params):\n",
    "    # 将标准输出流重定向到空设备\n",
    "    original_stdout =  sys.stdout\n",
    "    sys.stdout = open('log_maple.txt', 'w')\n",
    "    handle(**params)\n",
    "    sys.stdout = original_stdout\n",
    "    logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "tts(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户：                              \n",
      " ****************************************\n",
      "      您的对话已超时，请重新对话！\n",
      "\n",
      " ****************************************\n"
     ]
    }
   ],
   "source": [
    "#拜拜结束对话\n",
    "#对话前删除临时录音文件\n",
    "def delete_files(folder_path):\n",
    "    file_list = glob.glob(folder_path + '/*')\n",
    "    for file_path in file_list:\n",
    "        if os.path.isfile(file_path):\n",
    "            if '.' in file_path and file_path.split('.')[0].split('/')[-1][:4]=='test':\n",
    "                os.remove(file_path)\n",
    "\n",
    "# 调用函数删除文件夹中的文件\n",
    "audio_file_path = 'test'\n",
    "delete_files(audio_file_path)\n",
    "\n",
    "#语音提醒可以对话了\n",
    "params['text'] =\"您好，您现在可以跟我进行对话了！\" \n",
    "tts(params)\n",
    "\n",
    "#用户说一次话并得到机器回复即为一轮。用户一轮说话中每有一个相对长的间隔，则将前面的录音分割为独立的一段，这一段视为一波录音。\n",
    "outfile_name=audio_file_path+'\\\\test.mp3'\n",
    "lc =0 #对话轮次，用于录音文件的名称存储\n",
    "while(True):\n",
    "    filenum=0 #每轮对话的录音波次\n",
    "    tag=0 #一轮对话开始的标志\n",
    "    sign=0 #whisper类是否转换声音了\n",
    "    lc_result=''#每一轮次的语音输入结果\n",
    "\n",
    "    while(model_choose !='sherpa_onnx'):\n",
    "        temp=outfile_name.split('.')\n",
    "        #当前波次有说话时，若后面说话间隔超过delayTime时进行下一波次录音；若当前波次还没有语音，当时间间隔超过tendure时候结束本轮录音。\n",
    "\n",
    "        #增加用户的反应时间，3s太短了。\n",
    "        sign, tag=listen(temp[0]+str(lc)+str('-')+str(filenum)+'.'+temp[1], tag, delayTime=0.8, tendure=5, mindb = 2000)\n",
    "        # print(tag)\n",
    "        if sign==1:#一轮对话录音结束的标志,每轮最后一波不转文字\n",
    "            # if tag==0: #如果第一波录音算是反应时间\n",
    "            #     continue\n",
    "            break\n",
    "        else:\n",
    "            #将该波次语音转为文字\n",
    "            # print(1,end='')\n",
    "            open_audio_file = '/'.join(outfile_name.split('//'))\n",
    "            open_audio_file=open_audio_file.split('.')\n",
    "            open_audio_file = open_audio_file[0]+str(lc)+str('-')+str(filenum)+'.'+open_audio_file[1]\n",
    "            # print(1,end='')\n",
    "            #---------------有声音，但是不是话语时候，fast_whisper会输出随机的词语。\n",
    "            if model_choose=='faster_whisper':\n",
    "                result = fast_whisper_opt(model, open_audio_file, initial_prompt=None)\n",
    "            #------------------whisper听到声音，但是这些声音是语气词无法翻译成话语时候会出错。\n",
    "            elif model_choose=='whisper':\n",
    "                result = whisper_output(model, open_audio_file, initial_prompt=None)\n",
    "            #当对话是刚开始的时候\n",
    "            # print(2,end='')\n",
    "    \n",
    "            lc_result += result\n",
    "            # lc_result += ','\n",
    "            if re.sub(r'[ .。！!?？-]','', result) in {'拜拜', '再见','byebye', 'Byebye' ,'掰掰'}:\n",
    "                print(result)\n",
    "                lc=-1\n",
    "                break\n",
    "\n",
    "            print(result, end='')\n",
    "        filenum += 1\n",
    "\n",
    "    #注意：每轮最后一波录音是空白\n",
    "\n",
    "    if sign==1 and tag==0:#当用户开始说话但是无语音输入时候，退出整个对话\n",
    "        print('\\n', '*'*40)\n",
    "        print(' '*5, '您的对话已超时，请重新对话！')\n",
    "        print('\\n', '*'*40)\n",
    "        break\n",
    "    #----------------------------------------------------------------------------#\n",
    "    #shepra_onnx asr模型，快，但是不那么准确\n",
    "    #输入声音但是无法翻译成话语时候会直接结束对话\n",
    "    if model_choose == 'sherpa_onnx':\n",
    "        # print('用户:  请输入你的问题')\n",
    "        last_result, lc_result = microphone_endpoint.main(args_dict, False, check_recognizer)\n",
    "        if last_result in {'拜拜'}:\n",
    "            lc=-1\n",
    "            result=last_result\n",
    "        \n",
    "        if len(lc_result)==0:\n",
    "            print('\\n', '*'*40)\n",
    "            print(' '*5, '您的对话已超时，请重新对话！')\n",
    "            print('\\n', '*'*40)\n",
    "            break\n",
    "\n",
    "    print()\n",
    "    #每轮的文本互动开始\n",
    "    print('Bot:',end='')\n",
    "    if lc==-1:\n",
    "        print(result)\n",
    "        break\n",
    "    lc +=1\n",
    "\n",
    "    #文本对话\n",
    "    stream = ollama.chat(\n",
    "        model=text_text_model,\n",
    "        messages=[{'role': 'user', 'content': lc_result}],\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    outword=\"\"\n",
    "    outword3=\"\"\n",
    "\n",
    "    max_chunk=4#每max_chunk轮播放一次\n",
    "    chunk_num=1\n",
    "    for chunk in stream:\n",
    "        outword3 = chunk['message']['content']\n",
    "        #打印对话内容\n",
    "        print(outword3, end='', flush=True)\n",
    "        outword += outword3\n",
    "        #语音播放\n",
    "        if outword3 in {'\\n', ',','.','。','，','!','！', '?', '？',':', '：'}:\n",
    "            #语音合成\n",
    "            # 将标准输出流重定向到空设备\n",
    "            #每max_chunk句就读一次\n",
    "            #chunk_num==max_chunk:\n",
    "\n",
    "            #每换一次行第一次。\n",
    "            if outword3=='\\n':\n",
    "                params['text']=outword\n",
    "                tts(params)\n",
    "                # engine.say(outword)\n",
    "                outword=\"\"\n",
    "                chunk_num=1\n",
    "            #gemma是一个字一个chunk\n",
    "            else:\n",
    "                chunk_num +=1\n",
    "        # engine.runAndWait()\n",
    "\n",
    "    #把没凑够max_chunk的话读出来\n",
    "    if len(outword)!=0:\n",
    "        params['text']=outword\n",
    "        tts(params)\n",
    "    print('####end', end='')\n",
    "    params['text'] ='我的回答就是这些。'\n",
    "    tts(params)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
