{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 03:40:53,833 - modelscope - INFO - initiate model from E:\\LargeModel\\Speech_to_Text\\Funasr\\iic\\speech_paraformer-large-vad-punc-spk_asr_nat-zh-cn\n",
      "2024-04-08 03:40:53,835 - modelscope - INFO - initiate model from location E:\\LargeModel\\Speech_to_Text\\Funasr\\iic\\speech_paraformer-large-vad-punc-spk_asr_nat-zh-cn.\n",
      "2024-04-08 03:40:53,840 - modelscope - INFO - initialize model from E:\\LargeModel\\Speech_to_Text\\Funasr\\iic\\speech_paraformer-large-vad-punc-spk_asr_nat-zh-cn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt: E:\\LargeModel\\Speech_to_Text\\Funasr\\iic\\speech_paraformer-large-vad-punc-spk_asr_nat-zh-cn\\model.pt\n",
      "ckpt: E:\\LargeModel\\Speech_to_Text\\Funasr\\iic\\speech_fsmn_vad_zh-cn-16k-common-pytorch\\model.pt\n",
      "ckpt: E:\\LargeModel\\Speech_to_Text\\Funasr\\iic\\punc_ct-transformer_cn-en-common-vocab471067-large\\model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 03:41:30,723 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-04-08 03:41:30,724 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-04-08 03:41:30,725 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': 'E:\\\\LargeModel\\\\Speech_to_Text\\\\Funasr\\\\iic\\\\speech_paraformer-large-vad-punc-spk_asr_nat-zh-cn'}. trying to build by task and model information.\n",
      "2024-04-08 03:41:30,726 - modelscope - WARNING - No preprocessor key ('funasr', 'auto-speech-recognition') found in PREPROCESSOR_MAP, skip building preprocessor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt: iic/speech_campplus_sv_zh-cn_16k-common\\campplus_cn_common.bin\n"
     ]
    }
   ],
   "source": [
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "import sys\n",
    "\n",
    "audio_in = r\"E:\\LargeModel\\Speech_to_Text\\Fast_whisper\\test.wav\"\n",
    "output_dir = \"./results\"\n",
    "inference_pipeline = pipeline(\n",
    "    task=Tasks.auto_speech_recognition,\n",
    "    model=r\"E:\\LargeModel\\Speech_to_Text\\Funasr\\iic\\speech_paraformer-large-vad-punc-spk_asr_nat-zh-cn\",\n",
    "    model_revision='v2.0.4',\n",
    "    vad_model=r\"E:\\LargeModel\\Speech_to_Text\\Funasr\\iic\\speech_fsmn_vad_zh-cn-16k-common-pytorch\", vad_model_revision=\"v2.0.4\",\n",
    "    punc_model=r\"E:\\LargeModel\\Speech_to_Text\\Funasr\\iic\\punc_ct-transformer_cn-en-common-vocab471067-large\", punc_model_revision=\"v2.0.4\",\n",
    "    output_dir=output_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.192: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:01<00:00,  1.14s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "rtf_avg: 0.205:  20%|\u001b[34m██        \u001b[0m| 1/5 [00:11<00:46, 11.73s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "rtf_avg: 0.096:  12%|\u001b[34m█▎        \u001b[0m| 1/8 [00:01<00:08,  1.19s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "rtf_avg: 0.081:   9%|\u001b[34m▉         \u001b[0m| 1/11 [00:01<00:13,  1.35s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "rtf_avg: 0.022:   8%|\u001b[34m▊         \u001b[0m| 1/12 [00:01<00:16,  1.52s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "rtf_avg: 0.019:   7%|\u001b[34m▋         \u001b[0m| 1/15 [00:01<00:26,  1.89s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "rtf_avg: 0.005:   4%|\u001b[34m▍         \u001b[0m| 1/26 [00:03<01:25,  3.43s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "rtf_avg: -0.840: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.18it/s]\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "rtf_avg: 0.341, time_speech:  65.829, time_escape: 22.439: 100%|\u001b[31m██████████\u001b[0m| 1/1 [00:22<00:00, 22.50s/it]\n"
     ]
    }
   ],
   "source": [
    "rec_result = inference_pipeline(audio_in, batch_size_s=300, batch_size_token_threshold_s=40)\n",
    "# print(rec_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_convert(tsecond):\n",
    "    '''\n",
    "    将秒转为时:分:秒,毫秒的形式\n",
    "    '''\n",
    "    ms = tsecond-int(tsecond)\n",
    "    tsecond = int(tsecond)\n",
    "    hour = tsecond//3600\n",
    "    minute = tsecond%3600//60\n",
    "    second = tsecond%60\n",
    "    return(str(hour).rjust(2,'0')+':'+str(minute).rjust(2,'0')+':'+str(second).rjust(2,'0')+','+str(round(ms*1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "num=1\n",
    "# 在输入音频的文件位置生成一个同名的字幕文件\n",
    "srt_file = '.'.join(audio_in.split('.')[:-1])+'.srt'\n",
    "orign = sys.stdout \n",
    "sys.stdout = open(srt_file, 'w')\n",
    "for content in rec_result[0]['sentence_info']:\n",
    "    text = content['text']\n",
    "    start = content['start']/1000\n",
    "    end=content['end']/1000\n",
    "    spk = content['spk']\n",
    "    print(\"%d\\n%s --> %s\\n%s [%s]\" % (num, time_convert(start), time_convert(end), text, 'S'+str(spk)))\n",
    "    num+=1\n",
    "sys.stdout = orign "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
