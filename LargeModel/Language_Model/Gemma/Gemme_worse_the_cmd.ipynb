{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ollama聊天模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ollama\n",
    "import ollama\n",
    "import re\n",
    "messages =[]\n",
    "#加上system很快爆内存\n",
    "# messages = [{'role':'system','content':'你将用尽可能简洁的语言与用户聊天'}]\n",
    "while (True):\n",
    "  question = input()\n",
    "  if len(messages)>=8:\n",
    "    for i in range(2):\n",
    "      messages.pop(1)\n",
    "  if len(question)==0:\n",
    "    break\n",
    "  #gemma:2b, qwen:4b-chat-v1.5-q6_K，qwen:7b-chat, qwen:14b-chat\n",
    "  #gemma:7b-instruct-q8_0\n",
    "  messages.append({'role': 'user', 'content': question})\n",
    "  # messages[{'role': 'user', 'content': question}]\n",
    "  print('用户：', question)\n",
    "  print('Bot：', end='')\n",
    "  stream = ollama.chat(\n",
    "      # model='qwen:4b-chat-v1.5-q6_K',#可以长多轮对话，速度也挺快\n",
    "      model='qwen:7b-chat-v1.5-q5_0',#跟14b一样对话轮次少\n",
    "      # model='qwen:14b-chat',\n",
    "      messages=messages,\n",
    "      stream=True,\n",
    "      #option中的参数含义：https://github.com/ggerganov/llama.cpp/tree/master/examples/main#number-of-tokens-to-predict\n",
    "      options={\n",
    "      'num_predict': 128,#生成的最大tokens数,default:128\n",
    "      'temperature': 0.7,#default:0.9\n",
    "      # 'top_p': 0.9,\n",
    "      # 'top_k':20#defalut:40\n",
    "      }\n",
    "  )\n",
    "  outword=\"\"\n",
    "  num=0\n",
    "  for chunk in stream:\n",
    "    result = chunk['message']['content']\n",
    "    result = re.sub('\\n+','\\n', result) \n",
    "    outword+=result\n",
    "    print(result, end='', flush=True)\n",
    "    num+=1\n",
    "  # print(stream['message']['content'],flush=True)\n",
    "  messages.append({'role': 'assistant','content':outword})\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 常规输入模型转为Promot格式--ollama似乎不需要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(input_list, is_translate=True, is_input=True):\n",
    "    '''\n",
    "    将input_list转为Promot格式\n",
    "    is_translate:是否进行转换\n",
    "    '''\n",
    "    if not is_translate:\n",
    "        return(input_list)\n",
    "    input_list_copy = input_list.copy()\n",
    "    start = \"<|im_start|>\"\n",
    "    end= \"<|im_end|>\"\n",
    "    for index in range(len(input_list_copy)):\n",
    "        if type(input_list_copy[index]) == dict:\n",
    "            input_list_copy[index]=(f\"{start}{input_list_copy[index]['role']}\\n{input_list_copy[index]['content']}{end}\\n\")\n",
    "    if is_input:\n",
    "        input_list_copy.append(f\"{start}{'assistant'}\\n\")\n",
    "    return(input_list_copy)\n",
    "\n",
    "messages = [{'role':'system','content':'你被邀请来陪用户聊天'}]\n",
    "messages.append({'role': 'user', 'content': \"你能跟我聊天吗\"})\n",
    "print(''.join(translate(messages)))\n",
    "print('*'*40)\n",
    "outword='''对不起，我不知道你的名字是什么。'''\n",
    "messages.append({'role': 'assistant','content':outword})\n",
    "print(''.join(translate(messages, is_input=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ai回复并发声"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def text_voice(engine, rate=-1, volume=-1, voice=-1):\n",
    "    '''\n",
    "    三个参数：\n",
    "    rate:速率\n",
    "    volume:音量，【0,1】\n",
    "    voice:声音，0为男声，1为女声\n",
    "    '''\n",
    "    if rate!=-1:\n",
    "        engine.setProperty('rate', rate)\n",
    "    if volume!=-1:\n",
    "        engine.setProperty('volume',volume)\n",
    "    if voice!=-1:\n",
    "        voices = engine.getProperty('voices')       \n",
    "        engine.setProperty('voice', voices[voice].id)\n",
    "    return engine\n",
    "\n",
    "#pyttsx3无法说话\n",
    "import pyttsx3\n",
    "engine = pyttsx3.init()\n",
    "engine = text_voice(engine, rate=130)\n",
    "(r,ve,vs) = (engine.getProperty('rate'),engine.getProperty('volume'), engine.getProperty('voices'))\n",
    "print('目前语速是：',r,'\\t','语音音量是:',ve)\n",
    "\n",
    "\n",
    "import ollama\n",
    "# import speech\n",
    "stream = ollama.chat(\n",
    "    model='gemma:2b',\n",
    "    messages=[{'role': 'user', 'content': 'do you have a happy memorary'}],\n",
    "    stream=True,\n",
    ")\n",
    "outword2=\"\"\n",
    "outword=\"\"\n",
    "outword3=\"\"\n",
    "\n",
    "for chunk in stream:\n",
    "    outword3 = chunk['message']['content']\n",
    "    outword2 += outword3\n",
    "    outword += outword3\n",
    "    #语音播放\n",
    "    if outword3 in {',','.','。','，','!','！', '?', '？',':', '：'}:\n",
    "        outword = outword.replace('\\n','').replace('*','')\n",
    "        # speech.say(outword)\n",
    "        engine.say(outword)\n",
    "        \n",
    "        outword=\"\"\n",
    "    engine.runAndWait()\n",
    "    #打印对话内容\n",
    "    print(outword3, end='', flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
